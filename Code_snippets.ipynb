{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUykD3eADKWW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pgs_id = \"PGS000001\""
      ],
      "metadata": {
        "id": "gYz8GXmUDpd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = requests.get(f\"https://www.pgscatalog.org/rest/score/{pgs_id}\")"
      ],
      "metadata": {
        "id": "KUvRNAWfDQpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res.status_code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUZIK9Pa5kfd",
        "outputId": "48c328bb-d96d-48ac-b9b7-88b33c1cb156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pgs_res = res.json()"
      ],
      "metadata": {
        "id": "mHRS6SfoDzw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pgs_res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN0ih3oO5rtt",
        "outputId": "74b63e74-b8b5-47ec-987a-2f59a4f8df18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'PGS000001',\n",
              " 'name': 'PRS77_BC',\n",
              " 'ftp_scoring_file': 'https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/PGS000001/ScoringFiles/PGS000001.txt.gz',\n",
              " 'ftp_harmonized_scoring_files': {'GRCh37': {'positions': 'https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/PGS000001/ScoringFiles/Harmonized/PGS000001_hmPOS_GRCh37.txt.gz'},\n",
              "  'GRCh38': {'positions': 'https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/PGS000001/ScoringFiles/Harmonized/PGS000001_hmPOS_GRCh38.txt.gz'}},\n",
              " 'publication': {'id': 'PGP000001',\n",
              "  'title': 'Prediction of breast cancer risk based on profiling with common genetic variants.',\n",
              "  'doi': '10.1093/jnci/djv036',\n",
              "  'PMID': 25855707,\n",
              "  'journal': 'J Natl Cancer Inst',\n",
              "  'firstauthor': 'Mavaddat N',\n",
              "  'date_publication': '2015-04-08'},\n",
              " 'matches_publication': True,\n",
              " 'samples_variants': [{'sample_number': 22627,\n",
              "   'sample_cases': None,\n",
              "   'sample_controls': None,\n",
              "   'sample_percent_male': None,\n",
              "   'sample_age': None,\n",
              "   'phenotyping_free': None,\n",
              "   'followup_time': None,\n",
              "   'ancestry_broad': 'European',\n",
              "   'ancestry_free': None,\n",
              "   'ancestry_country': 'Finland, Sweden, U.S., Australia, Netherlands, Germany, U.K.',\n",
              "   'ancestry_additional': None,\n",
              "   'source_GWAS_catalog': 'GCST001937',\n",
              "   'source_PMID': 23535729,\n",
              "   'source_DOI': None,\n",
              "   'cohorts': [],\n",
              "   'cohorts_additional': None}],\n",
              " 'samples_training': [],\n",
              " 'trait_reported': 'Breast Cancer',\n",
              " 'trait_additional': None,\n",
              " 'trait_efo': [{'id': 'EFO_0000305',\n",
              "   'label': 'breast carcinoma',\n",
              "   'description': 'A carcinoma that arises from epithelial cells of the breast',\n",
              "   'url': 'http://www.ebi.ac.uk/efo/EFO_0000305'}],\n",
              " 'method_name': 'SNPs passing genome-wide significance',\n",
              " 'method_params': 'P<5x10-8',\n",
              " 'variants_number': 77,\n",
              " 'variants_interactions': 0,\n",
              " 'variants_genomebuild': 'NR',\n",
              " 'weight_type': 'NR',\n",
              " 'ancestry_distribution': {'eval': {'dist': {'EUR': 100}, 'count': 7},\n",
              "  'gwas': {'dist': {'EUR': 100}, 'count': 22627}},\n",
              " 'license': 'PGS obtained from the Catalog should be cited appropriately, and used in accordance with any licensing restrictions set by the authors. See EBI Terms of Use (https://www.ebi.ac.uk/about/terms-of-use/) for additional details.'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pgs_url = pgs_res[\"ftp_harmonized_scoring_files\"][\"GRCh37\"][\"positions\"]"
      ],
      "metadata": {
        "id": "PTN2HUiED1Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(pgs_url, comment=\"#\", sep=\"\\t\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iSqEqbkVD-1a",
        "outputId": "8b9fd79e-fd77-4493-e47e-f6ce9ffab9e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          rsID  chr_name effect_allele other_allele  effect_weight locus_name  \\\n",
              "0   rs78540526        11             T            C       0.162204      CCND1   \n",
              "1   rs75915166        11             A            C       0.023619      CCND1   \n",
              "2     rs554219        11             G            C       0.116716      CCND1   \n",
              "3    rs7726159         5             A            C       0.035271       TERT   \n",
              "4   rs10069690         5             T            C       0.023912       TERT   \n",
              "..         ...       ...           ...          ...            ...        ...   \n",
              "72   rs6001930        22             C            T       0.126192       MKL1   \n",
              "73   rs4245739         1             C            A       0.028685       MDM4   \n",
              "74   rs6678914         1             A            G      -0.011061       LGR6   \n",
              "75  rs12710696         2             A            G       0.037970     2p24.1   \n",
              "76  rs11075995        16             T            A       0.036139        FTO   \n",
              "\n",
              "        OR hm_source     hm_rsID  hm_chr     hm_pos  hm_inferOtherAllele  \n",
              "0   1.1761   ENSEMBL  rs78540526      11   69331418                  NaN  \n",
              "1   1.0239   ENSEMBL  rs75915166      11   69379161                  NaN  \n",
              "2   1.1238   ENSEMBL    rs554219      11   69331642                  NaN  \n",
              "3   1.0359   ENSEMBL   rs7726159       5    1282319                  NaN  \n",
              "4   1.0242   ENSEMBL  rs10069690       5    1279790                  NaN  \n",
              "..     ...       ...         ...     ...        ...                  ...  \n",
              "72  1.1345   ENSEMBL   rs6001930      22   40876234                  NaN  \n",
              "73  1.0291   ENSEMBL   rs4245739       1  204518842                  NaN  \n",
              "74  0.9890   ENSEMBL   rs6678914       1  202187176                  NaN  \n",
              "75  1.0387   ENSEMBL  rs12710696       2   19320803                  NaN  \n",
              "76  1.0368   ENSEMBL  rs11075995      16   53855291                  NaN  \n",
              "\n",
              "[77 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57001779-4260-418b-8d3f-7181670d3504\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rsID</th>\n",
              "      <th>chr_name</th>\n",
              "      <th>effect_allele</th>\n",
              "      <th>other_allele</th>\n",
              "      <th>effect_weight</th>\n",
              "      <th>locus_name</th>\n",
              "      <th>OR</th>\n",
              "      <th>hm_source</th>\n",
              "      <th>hm_rsID</th>\n",
              "      <th>hm_chr</th>\n",
              "      <th>hm_pos</th>\n",
              "      <th>hm_inferOtherAllele</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rs78540526</td>\n",
              "      <td>11</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>0.162204</td>\n",
              "      <td>CCND1</td>\n",
              "      <td>1.1761</td>\n",
              "      <td>ENSEMBL</td>\n",
              "      <td>rs78540526</td>\n",
              "      <td>11</td>\n",
              "      <td>69331418</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rs75915166</td>\n",
              "      <td>11</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>0.023619</td>\n",
              "      <td>CCND1</td>\n",
              "      <td>1.0239</td>\n",
              "      <td>ENSEMBL</td>\n",
              "      <td>rs75915166</td>\n",
              "      <td>11</td>\n",
              "      <td>69379161</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rs554219</td>\n",
              "      <td>11</td>\n",
              "      <td>G</td>\n",
              "      <td>C</td>\n",
              "      <td>0.116716</td>\n",
              "      <td>CCND1</td>\n",
              "      <td>1.1238</td>\n",
              "      <td>ENSEMBL</td>\n",
              "      <td>rs554219</td>\n",
              "      <td>11</td>\n",
              "      <td>69331642</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rs7726159</td>\n",
              "      <td>5</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>0.035271</td>\n",
              "      <td>TERT</td>\n",
              "      <td>1.0359</td>\n",
              "      <td>ENSEMBL</td>\n",
              "      <td>rs7726159</td>\n",
              "      <td>5</td>\n",
              "      <td>1282319</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rs10069690</td>\n",
              "      <td>5</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>0.023912</td>\n",
              "      <td>TERT</td>\n",
              "      <td>1.0242</td>\n",
              "      <td>ENSEMBL</td>\n",
              "      <td>rs10069690</td>\n",
              "      <td>5</td>\n",
              "      <td>1279790</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>rs6001930</td>\n",
              "      <td>22</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>0.126192</td>\n",
              "      <td>MKL1</td>\n",
              "      <td>1.1345</td>\n",
              "      <td>ENSEMBL</td>\n",
              "      <td>rs6001930</td>\n",
              "      <td>22</td>\n",
              "      <td>40876234</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>rs4245739</td>\n",
              "      <td>1</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>0.028685</td>\n",
              "      <td>MDM4</td>\n",
              "      <td>1.0291</td>\n",
              "      <td>ENSEMBL</td>\n",
              "      <td>rs4245739</td>\n",
              "      <td>1</td>\n",
              "      <td>204518842</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>rs6678914</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>-0.011061</td>\n",
              "      <td>LGR6</td>\n",
              "      <td>0.9890</td>\n",
              "      <td>ENSEMBL</td>\n",
              "      <td>rs6678914</td>\n",
              "      <td>1</td>\n",
              "      <td>202187176</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>rs12710696</td>\n",
              "      <td>2</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>0.037970</td>\n",
              "      <td>2p24.1</td>\n",
              "      <td>1.0387</td>\n",
              "      <td>ENSEMBL</td>\n",
              "      <td>rs12710696</td>\n",
              "      <td>2</td>\n",
              "      <td>19320803</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>rs11075995</td>\n",
              "      <td>16</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>0.036139</td>\n",
              "      <td>FTO</td>\n",
              "      <td>1.0368</td>\n",
              "      <td>ENSEMBL</td>\n",
              "      <td>rs11075995</td>\n",
              "      <td>16</td>\n",
              "      <td>53855291</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>77 rows Ã— 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57001779-4260-418b-8d3f-7181670d3504')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57001779-4260-418b-8d3f-7181670d3504 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57001779-4260-418b-8d3f-7181670d3504');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/PGScatalog/pgsc_calc/blob/main/docs/how-to/calculate_pgscatalog.rst#id5\n",
        "# https://www.pgscatalog.org/rest/\n",
        "\n",
        "\n",
        "def geneticRisk = fun(VCF,PGS_ID):\n",
        "  "
      ],
      "metadata": {
        "id": "4gWz6bgMEWBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "with gzip.open('input.vcf.gz', 'rb') as f:\n",
        "     for line in f:        \n",
        "         print(line)  "
      ],
      "metadata": {
        "id": "jqScQsnfnbFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FQxqpDw0nbN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "import polars as pl\n",
        "import argparse\n",
        "import sys\n",
        "import glob\n",
        "from typing import List, Dict, Union\n",
        "\n",
        "def parse_args(args=None):\n",
        "    parser = argparse.ArgumentParser(description='Read and format scoring files')\n",
        "    parser.add_argument('-d', '--dataset', dest='dataset', required=True,\n",
        "                        help='<Required> Label for target genomic dataset (e.g. \"-d thousand_genomes\")')\n",
        "    parser.add_argument('-s', '--scorefiles', dest='scorefile', required=True,\n",
        "                        help='<Required> Combined scorefile path (output of read_scorefiles.py)')\n",
        "    parser.add_argument('-t', '--target', dest='target', required=True,\n",
        "                        help='<Required> A table of target genomic variants (.bim format)')\n",
        "    parser.add_argument('--split', dest='split', default=False, action='store_true',\n",
        "                        help='<Required> Split scorefile per chromosome?')\n",
        "    parser.add_argument('-n', '--n_threads', dest='n_threads', default = 1, type=int,\n",
        "                        help='<Required> Number of threads used to match (default = 1)')\n",
        "    parser.add_argument('--format', required = True, dest='plink_format', help='<Required> bim or pvar?')\n",
        "    parser.add_argument('--db', dest='db', required = True, help='<Required> path to database')\n",
        "    parser.add_argument('-m', '--min_overlap', dest='min_overlap', required=True,\n",
        "                        type=float, help='<Required> Minimum proportion of variants to match before error')\n",
        "    parser.add_argument('--keep_ambiguous', dest='remove_ambiguous', action='store_false',\n",
        "                        help='Flag to force the program to keep variants with ambiguous alleles, (e.g. A/T and G/C '\n",
        "                             'SNPs), which are normally excluded (default: false). In this case the program proceeds assuming that the '\n",
        "                             'genotype data is on the same strand as the GWAS whose summary statistics were used to '\n",
        "                             'construct the score.'),\n",
        "    parser.add_argument('--keep_multiallelic', dest='remove_multiallelic', action='store_false',\n",
        "                        help='Flag to allow matching to multiallelic variants (default: false).')\n",
        "    return parser.parse_args(args)\n",
        "\n",
        "\n",
        "def read_pvarcolumns(path: str) -> List[str]:\n",
        "    \"\"\"Get the column names from the pvar file (not constrained like bim, especially when converted from VCF)\"\"\"\n",
        "    f_pvar: TextIO = open(path, 'rt')\n",
        "    line: str = '#'\n",
        "    header: List[str] = []\n",
        "    while line.startswith('#'):\n",
        "        line: str = f_pvar.readline()\n",
        "        if line.startswith('#CHROM'):\n",
        "            header = line.strip().split('\\t')\n",
        "    f_pvar.close()\n",
        "    return header\n",
        "\n",
        "\n",
        "def read_target(path: str, plink_format: str, remove_multiallelic: bool, n_threads: int) -> pl.DataFrame:\n",
        "    \"\"\"Complementing alleles with a pile of regexes seems weird, but polars string\n",
        "    functions are limited (i.e. no str.translate). Applying a python complement\n",
        "    function would be very slow compared to this, unless I develop a function\n",
        "    in rust. I don't know rust, and I stole the regex idea from Scott.\n",
        "    \"\"\"\n",
        "    if plink_format == 'bim':\n",
        "        # set chr_name to be str, fixes vstacking problem with inferred dtypes\n",
        "        # ( chr1 + chr2 + chrX = boom )\n",
        "        x: pl.DataFrame = pl.read_csv(path, sep='\\t', has_header=False, n_threads = n_threads,\n",
        "                                      dtype = {'column_1': str})\n",
        "        x.columns = ['#CHROM', 'ID', 'CM', 'POS', 'REF', 'ALT']\n",
        "        x = x[['#CHROM', 'POS', 'ID', 'REF', 'ALT']]  # subset to matching columns\n",
        "    else:\n",
        "        # plink2 pvar may have VCF comments in header starting ##\n",
        "        x: pl.DataFrame = pl.read_csv(path, sep='\\t', has_header=False, comment_char='#',\n",
        "                                      dtype = {'column_1': str}, n_threads = n_threads)\n",
        "\n",
        "        # read pvar header\n",
        "        x.columns = read_pvarcolumns(glob.glob(path)[0])  # guess from the first file\n",
        "        x = x[['#CHROM', 'POS', 'ID', 'REF', 'ALT']]  # subset to matching columns\n",
        "\n",
        "        # Handle multi-allelic variants\n",
        "        is_ma: pl.Series = x['ALT'].str.contains(',')  # plink2 pvar multi-alleles are comma-separated\n",
        "        if is_ma.sum() > 0:\n",
        "            if remove_multiallelic:\n",
        "                print('Dropping Multiallelic variants')\n",
        "                x = x[~is_ma]\n",
        "            else:\n",
        "                x.replace('ALT', x['ALT'].str.split(by=','))  # turn ALT to list of variants\n",
        "                x = x.explode('ALT')  # expand the DF to have all the variants in different rows\n",
        "\n",
        "    x = x.with_columns([\n",
        "        (pl.col(\"REF\").str.replace_all(\"A\", \"V\")\n",
        "         .str.replace_all(\"T\", \"X\")\n",
        "         .str.replace_all(\"C\", \"Y\")\n",
        "         .str.replace_all(\"G\", \"Z\")\n",
        "         .str.replace_all(\"V\", \"T\")\n",
        "         .str.replace_all(\"X\", \"A\")\n",
        "         .str.replace_all(\"Y\", \"G\")\n",
        "         .str.replace_all(\"Z\", \"C\"))\n",
        "            .alias(\"REF_FLIP\"),\n",
        "        (pl.col(\"ALT\").str.replace_all(\"A\", \"V\")\n",
        "         .str.replace_all(\"T\", \"X\")\n",
        "         .str.replace_all(\"C\", \"Y\")\n",
        "         .str.replace_all(\"G\", \"Z\")\n",
        "         .str.replace_all(\"V\", \"T\")\n",
        "         .str.replace_all(\"X\", \"A\")\n",
        "         .str.replace_all(\"Y\", \"G\")\n",
        "         .str.replace_all(\"Z\", \"C\"))\n",
        "            .alias(\"ALT_FLIP\")\n",
        "    ])\n",
        "\n",
        "    return x.with_columns([\n",
        "        pl.col(\"REF\").cast(pl.Categorical),\n",
        "        pl.col(\"ALT\").cast(pl.Categorical),\n",
        "        pl.col(\"ALT_FLIP\").cast(pl.Categorical),\n",
        "        pl.col(\"REF_FLIP\").cast(pl.Categorical)])\n",
        "\n",
        "\n",
        "def read_scorefile(path: str) -> pl.DataFrame:\n",
        "    scorefile: pl.DataFrame = pl.read_csv(path, sep='\\t', dtype = {'chr_name': str})\n",
        "\n",
        "    assert all((scorefile.groupby(['accession', 'chr_name', 'chr_position', 'effect_allele'])\n",
        "               .count()['count']) == 1), \"Multiple effect weights per variant per accession!\"\n",
        "\n",
        "    return scorefile.with_columns([\n",
        "        pl.col(\"effect_allele\").cast(pl.Categorical),\n",
        "        pl.col(\"other_allele\").cast(pl.Categorical),\n",
        "        pl.col(\"effect_type\").cast(pl.Categorical),\n",
        "        pl.col(\"accession\").cast(pl.Categorical)\n",
        "    ])\n",
        "\n",
        "\n",
        "def match_variants(scorefile: pl.DataFrame,\n",
        "                   target: pl.DataFrame,\n",
        "                   EA: str,\n",
        "                   OA: str,\n",
        "                   match_type: str) -> pl.DataFrame:\n",
        "    colnames: List[str] = ['chr_name', 'chr_position', 'effect_allele', 'other_allele', 'effect_weight', 'effect_type',\n",
        "                           'accession', 'ID', 'REF', 'ALT', 'REF_FLIP', 'ALT_FLIP', 'match_type']\n",
        "\n",
        "    if OA:\n",
        "        matches: pl.DataFrame = scorefile.join(target,\n",
        "                                               left_on=['chr_name', 'chr_position', 'effect_allele', 'other_allele'],\n",
        "                                               right_on=['#CHROM', 'POS', EA, OA], how='inner').with_columns([\n",
        "            pl.col(\"*\"),\n",
        "            pl.col(\"effect_allele\").alias(EA),  # copy the column that's dropped by join\n",
        "            pl.col(\"other_allele\").alias(OA),\n",
        "            pl.lit(match_type).alias(\"match_type\")\n",
        "        ])\n",
        "        # join removes matching key, reorder columns for vertical stacking (pl.concat)\n",
        "        # collecting is needed for reordering columns\n",
        "    else:\n",
        "        matches: pl.DataFrame = scorefile.join(target,\n",
        "                                                       left_on=['chr_name', 'chr_position', 'effect_allele'],\n",
        "                                                       right_on=['#CHROM', 'POS', EA], how='inner').with_columns([\n",
        "                    pl.col(\"*\"),\n",
        "                    pl.col(\"effect_allele\").alias(EA),  # copy the column that's dropped by join\n",
        "                    pl.lit(match_type).alias(\"match_type\")\n",
        "                ])\n",
        "\n",
        "    return matches[colnames]\n",
        "\n",
        "\n",
        "def get_all_matches(target: pl.DataFrame, scorefile: pl.DataFrame, remove_ambig: bool) -> pl.DataFrame:\n",
        "    \"\"\" Get intersection of variants using four different schemes, optionally\n",
        "    removing ambiguous variants (default: true)\n",
        "    scorefile      | target | scorefile   |  target\n",
        "    effect_allele == REF and other_allele == ALT\n",
        "    effect_allele == ALT and other_allele == REF\n",
        "    effect_allele == flip(REF) and other_allele == flip(ALT)\n",
        "    effect_allele == flip(REF) and oher_allele ==  flip(REF)\n",
        "    If not removing ambiguous variants, then it's assumed that the genotype data\n",
        "    is on the same strand as the GWAS whose summary statistics were used to\n",
        "    construct the score\n",
        "    If other_allele is missing, match only using effect_allele using the same process\n",
        "    \"\"\"\n",
        "\n",
        "    scorefile_oa = scorefile.filter(pl.col(\"other_allele\") != None)\n",
        "    scorefile_no_oa = scorefile.filter(pl.col(\"other_allele\") == None)\n",
        "\n",
        "    matches: Dict[str, pl.DataFrame] = {}\n",
        "\n",
        "    if scorefile_oa:\n",
        "        matches['refalt'] = match_variants(scorefile, target, EA='REF', OA='ALT', match_type=\"refalt\")\n",
        "        matches['altref'] = match_variants(scorefile, target, EA='ALT', OA='REF', match_type=\"altref\")\n",
        "        matches['refalt_flip'] = match_variants(scorefile, target, EA='REF_FLIP', OA='ALT_FLIP', match_type=\"refalt_flip\")\n",
        "        matches['altref_flip'] = match_variants(scorefile, target, EA='ALT_FLIP', OA='REF_FLIP', match_type=\"altref_flip\")\n",
        "\n",
        "    if scorefile_no_oa:\n",
        "        matches['no_oa_ref'] = match_variants(scorefile_no_oa, target, EA='REF', OA=None, match_type=\"no_oa_ref\")\n",
        "        matches['no_oa_alt'] = match_variants(scorefile_no_oa, target, EA='ALT', OA=None, match_type=\"no_oa_alt\")\n",
        "        matches['no_oa_ref_flip'] = match_variants(scorefile_no_oa, target, EA='REF_FLIP', OA=None, match_type=\"no_oa_ref_flip\")\n",
        "        matches['no_oa_alt_flip'] = match_variants(scorefile_no_oa, target, EA='ALT_FLIP', OA=None, match_type=\"no_oa_alt_flip\")\n",
        "\n",
        "    ambig_labelled: pl.DataFrame = label_biallelic_ambiguous(pl.concat(list(matches.values())))\n",
        "\n",
        "    # no. of matches should never be more than the no. of variants in scorefile\n",
        "    input_count = scorefile.groupby(['accession']).count().sort('accession')\n",
        "    match_count = ambig_labelled.groupby(['accession']).count().sort('accession')\n",
        "    assert all(input_count['count'] >= match_count['count'])\n",
        "\n",
        "    if remove_ambig:\n",
        "        print('Removing Ambiguous Matches')\n",
        "        return ambig_labelled.filter(pl.col(\"ambiguous\") == False)\n",
        "    else:\n",
        "        # pick the best possible match from the ambiguous matches\n",
        "        # EA = REF and OA = ALT or EA = REF and OA = None\n",
        "        ambig: pl.DataFrame = ambig_labelled.filter((pl.col(\"ambiguous\") == True) & \\\n",
        "                                                    (pl.col(\"match_type\") == \"refalt\") |\n",
        "                                                    (pl.col(\"ambiguous\") == True) & \\\n",
        "                                                    (pl.col(\"match_type\") == \"no_oa_ref\"))\n",
        "        unambig: pl.DataFrame = ambig_labelled.filter(pl.col(\"ambiguous\") == False)\n",
        "        return pl.concat([ambig, unambig])\n",
        "\n",
        "def get_distinct_weights(df: pl.DataFrame) -> pl.DataFrame:\n",
        "    \"\"\" Get a single effect weight for each matched variant per accession \"\"\"\n",
        "    count: pl.DataFrame = df.groupby(['accession', 'chr_name', 'chr_position', 'effect_allele']).count()\n",
        "    singletons: pl.DataFrame = (count.filter(pl.col('count') == 1)[:,\"accession\":\"effect_allele\"]\n",
        "            .join(df, on = ['accession', 'chr_name', 'chr_position', 'effect_allele'], how = 'left'))\n",
        "\n",
        "    # TODO: something more complex than .unique()?\n",
        "    # prioritise unambiguous -> ref -> alt -> ref_flip -> alt_flip\n",
        "    dups: pl.DataFrame = (count.filter(pl.col('count') > 1)[:,\"accession\":\"effect_allele\"]\n",
        "            .join(df, on = ['accession', 'chr_name', 'chr_position', 'effect_allele'], how = 'left')\n",
        "            .unique(subset = ['accession', 'chr_name', 'chr_position', 'effect_allele']))\n",
        "    distinct: pl.DataFrame = pl.concat([singletons, dups])\n",
        "\n",
        "    assert all((distinct.groupby(['accession', 'chr_name', 'chr_position', 'effect_allele'])\n",
        "                .count()['count']) == 1), \"Duplicate effect weights for a variant\"\n",
        "\n",
        "    return distinct\n",
        "\n",
        "def label_biallelic_ambiguous(matches: pl.DataFrame) -> pl.DataFrame:\n",
        "    # A / T or C / G may match multiple times\n",
        "    matches = matches.with_columns([\n",
        "        pl.col([\"effect_allele\", \"other_allele\", \"REF\", \"ALT\", \"REF_FLIP\", \"ALT_FLIP\"]).cast(str),\n",
        "        pl.lit(True).alias(\"ambiguous\")\n",
        "    ])\n",
        "\n",
        "    return get_distinct_weights(matches.with_column(\n",
        "        pl.when((pl.col(\"effect_allele\") == pl.col(\"ALT_FLIP\")) |\n",
        "                (pl.col(\"effect_allele\") == pl.col(\"REF_FLIP\")))\n",
        "            .then(pl.col(\"ambiguous\"))\n",
        "            .otherwise(False)))\n",
        "\n",
        "\n",
        "def unduplicate_variants(df: pl.DataFrame) -> List[pl.DataFrame]:\n",
        "    \"\"\" Find variant matches that have duplicate identifiers\n",
        "    When merging a lot of scoring files, sometimes a variant might be duplicated\n",
        "    this can happen when the effect allele differs at the same position, e.g.:\n",
        "        - chr1: chr2:20003:A:C A 0.3 NA\n",
        "        - chr1: chr2:20003:A:C C NA 0.7\n",
        "    where the last two columns represent different scores.  plink demands\n",
        "    unique identifiers! so need to split, score, and sum later\n",
        "    Parameters:\n",
        "    df: A dataframe containing all matches, with columns ID, effect_allele, and\n",
        "        effect_weight\n",
        "    Returns:\n",
        "        A list of dataframes, with unique ID - effect allele combinations\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. unique ID - EA is important because normal duplicates are already ----\n",
        "    #   handled by pivoting, and it's pointless to split them unnecessarily\n",
        "    # 2. use cumcount to number duplicate IDs\n",
        "    # 3. join cumcount data on original DF, use this data for splitting\n",
        "    ea_count: pl.DataFrame = (df.select([\"ID\", \"effect_allele\"])\n",
        "        .unique()\n",
        "        .with_columns([\n",
        "        pl.col(\"ID\").cumcount().over([\"ID\"]).alias(\"cumcount\"),\n",
        "        pl.col(\"ID\").count().over([\"ID\"]).alias(\"count\")\n",
        "    ]))\n",
        "\n",
        "    dup_label: pl.DataFrame = df.join(ea_count, on=[\"ID\", \"effect_allele\"], how=\"left\")\n",
        "\n",
        "    # now split the matched variants, and make sure we don't lose any ----------\n",
        "    n_splits: int = ea_count.select(\"cumcount\").max()[0, 0] + 1  # cumcount = ngroup-1\n",
        "    df_lst: list = []\n",
        "    n_var: int = 0\n",
        "\n",
        "    for i in range(0, n_splits):\n",
        "        x: pl.DataFrame = dup_label.filter(pl.col(\"cumcount\") == i)\n",
        "        n_var += x.shape[0]\n",
        "        df_lst.append(x)\n",
        "\n",
        "    assert n_var == df.shape[0]\n",
        "\n",
        "    return df_lst\n",
        "\n",
        "\n",
        "def format_scorefile(df: pl.DataFrame, split: bool) -> Dict[Union[int, str], pl.DataFrame]:\n",
        "    \"\"\" Format a dataframe to plink2 --score standard\n",
        "    Minimum example:\n",
        "    ID | effect_allele | effect_weight\n",
        "    Multiple scores are OK too:\n",
        "    ID | effect_allele | weight_1 | ... | weight_n\n",
        "    \"\"\"\n",
        "    if split:\n",
        "        chroms: List[int] = df[\"chr_name\"].unique().to_list()\n",
        "        return {x: (df.filter(pl.col(\"chr_name\") == x)\n",
        "                    .pivot(index=[\"ID\", \"effect_allele\"], values=\"effect_weight\", columns=\"accession\")\n",
        "                    .fill_null(pl.lit(0)))\n",
        "                for x in chroms}\n",
        "    else:\n",
        "        return {'false': (df.pivot(index=[\"ID\", \"effect_allele\"], values=\"effect_weight\", columns=\"accession\")\n",
        "                          .fill_null(pl.lit(0)))}\n",
        "\n",
        "\n",
        "def split_effect_type(df: pl.DataFrame) -> Dict[str, pl.DataFrame]:\n",
        "    effect_types: List[str] = df[\"effect_type\"].unique().to_list()\n",
        "    return {x: df.filter(pl.col(\"effect_type\") == x) for x in effect_types}\n",
        "\n",
        "\n",
        "def write_scorefile(effect_type: str, scorefiles: pl.DataFrame, split: bool) -> None:\n",
        "    \"\"\" Write a list of scorefiles with the same effect type \"\"\"\n",
        "    fout: str = '{chr}_{et}_{split}.scorefile'\n",
        "\n",
        "    # each list element contains a dataframe of variants\n",
        "    # lists are split to ensure variants have unique ID - effect alleles\n",
        "    for i, scorefile in enumerate(scorefiles):\n",
        "        df_dict: Dict[Union[int, str], pl.DataFrame] = format_scorefile(scorefile, split)  # may be split by chrom\n",
        "\n",
        "        for k, v in df_dict.items():\n",
        "            path: str = fout.format(chr=k, et=effect_type, split=i)\n",
        "            v.write_csv(path, sep=\"\\t\")\n",
        "\n",
        "\n",
        "def connect_db(path: str) -> str:\n",
        "    \"\"\" Set up sqlite3 connection \"\"\"\n",
        "    return 'sqlite://{}'.format(path)\n",
        "\n",
        "\n",
        "def read_log(conn: str) -> pl.DataFrame:\n",
        "    \"\"\" Read scorefile input log from database \"\"\"\n",
        "    query: str = 'SELECT * from scorefile'\n",
        "    return pl.read_sql(query, conn).with_columns([\n",
        "        pl.col(\"chr_name\").cast(str),\n",
        "        pl.col(\"accession\").cast(pl.Categorical),\n",
        "        pl.col(\"effect_type\").cast(pl.Categorical)\n",
        "    ])\n",
        "\n",
        "\n",
        "def join_log(logs: pl.DataFrame, match: pl.DataFrame, lifted: bool) -> pl.DataFrame:\n",
        "    \"\"\" Lifted scorefiles need to match the log using different chr_name chr_pos \"\"\"\n",
        "\n",
        "    if lifted:\n",
        "        return (logs.join(match,\n",
        "                          left_on=['lifted_chr', 'lifted_pos', 'effect_allele', 'other_allele',\n",
        "                                   'accession', 'effect_type', 'effect_weight'],\n",
        "                          right_on=['chr_name', 'chr_position', 'effect_allele', 'other_allele',\n",
        "                                    'accession', 'effect_type', 'effect_weight'], how='left'))\n",
        "    else:\n",
        "        return (logs.join(match,\n",
        "                          left_on=['chr_name', 'chr_position', 'effect_allele', 'other_allele',\n",
        "                                   'accession', 'effect_type', 'effect_weight'],\n",
        "                          right_on=['chr_name', 'chr_position', 'effect_allele', 'other_allele',\n",
        "                                    'accession', 'effect_type', 'effect_weight'], how='left'))\n",
        "\n",
        "\n",
        "def update_log(logs: pl.DataFrame,\n",
        "               matches: pl.DataFrame,\n",
        "               min_overlap: float,\n",
        "               dataset: str) -> None:\n",
        "    \"\"\" Read log and update with match data, write to csv \"\"\"\n",
        "\n",
        "    match_clean: pl.DataFrame = matches.drop(['REF', 'ALT', 'REF_FLIP', 'ALT_FLIP'])\n",
        "    unlifted_accessions: pl.DataFrame = logs[['accession', 'liftover']].unique().filter(pl.col('liftover') == None)\n",
        "    lifted_accessions: pl.DataFrame = logs[['accession', 'liftover']].unique().filter(pl.col('liftover') == 1)\n",
        "    matches = []\n",
        "\n",
        "    if lifted_accessions:\n",
        "        matches.append(join_log(logs, match_clean, lifted = True))\n",
        "\n",
        "    if unlifted_accessions:\n",
        "        matches.append(join_log(logs, match_clean, lifted = False))\n",
        "\n",
        "\n",
        "    match_log: pl.DataFrame = (pl.concat(matches)\n",
        "                               .with_columns([\n",
        "                                   pl.col('ambiguous').fill_null(True),\n",
        "                                   pl.lit(dataset).alias('dataset')\n",
        "                               ]))\n",
        "\n",
        "    match_log.write_csv('log.csv') # TODO: sqlite3 database?\n",
        "    check_match(match_log, min_overlap)\n",
        "\n",
        "\n",
        "def check_match(match_log: pl.DataFrame, min_overlap: float) -> None:\n",
        "    \"\"\" Explode if matching goes badly \"\"\"\n",
        "\n",
        "    fail_rates: pl.DataFrame = (match_log\n",
        "                                .groupby('accession')\n",
        "                                .agg([pl.count(), (pl.col('match_type') == None).sum().alias('no_match')])\n",
        "                                .with_column((pl.col('no_match') / pl.col('count')).alias('fail_rate'))\n",
        "                                )\n",
        "    for a, r in zip(fail_rates['accession'].to_list(), fail_rates['fail_rate'].to_list()):\n",
        "        err: str = \"ERROR: Score {} matches your variants badly. Check --min_overlap ({:.2%} min, {:.2%} match)\"\n",
        "        assert r < (1 - min_overlap), err.format(a, min_overlap, 1 - r)\n",
        "\n",
        "\n",
        "def main(args=None) -> None:\n",
        "    \"\"\" Match variants from scorefiles against target variant information \"\"\"\n",
        "    pl.Config.set_global_string_cache()\n",
        "    args: argparse.Namespace = parse_args(args)\n",
        "\n",
        "    assert args.plink_format in ['bim', 'pvar'], \"--format bim or --format pvar\"\n",
        "\n",
        "    # read inputs --------------------------------------------------------------\n",
        "    target: pl.DataFrame = read_target(args.target, args.plink_format,\n",
        "                                       args.remove_multiallelic, args.n_threads)\n",
        "    scorefile: pl.DataFrame = read_scorefile(args.scorefile)\n",
        "\n",
        "    # start matching -----------------------------------------------------------\n",
        "    matches: pl.DataFrame = get_all_matches(target, scorefile, args.remove_ambiguous)\n",
        "\n",
        "    empty_err: str = ''' ERROR: No target variants match any variants in all scoring files\n",
        "    This is quite odd!\n",
        "    Try checking the genome build (see --liftover and --target_build parameters)\n",
        "    Try imputing your microarray data if it doesn't cover the scoring variants well\n",
        "    '''\n",
        "    assert matches.shape[0] > 0, empty_err\n",
        "\n",
        "    # update logs --------------------------------------------------------------\n",
        "    conn: str = connect_db(args.db)\n",
        "    logs: pl.DataFrame = read_log(conn)\n",
        "    update_log(logs, matches, args.min_overlap, args.dataset)\n",
        "\n",
        "    # prepare for writing out --------------------------------------------------\n",
        "    # write one combined scorefile for efficiency, but need extra file for each:\n",
        "    #     - effect type (e.g. additive, dominant, or recessive)\n",
        "    #     - duplicated chr:pos:ref:alt ID (with different effect allele)\n",
        "    ets: Dict[str, pl.DataFrame] = split_effect_type(matches)\n",
        "    unduplicated: Dict[str, pl.DataFrame] = {k: unduplicate_variants(v) for k, v in ets.items()}\n",
        "    ea_dict: Dict[str, str] = {'is_dominant': 'dominant', 'is_recessive': 'recessive', 'additive': 'additive'}\n",
        "    [write_scorefile(ea_dict.get(k), v, args.split) for k, v in unduplicated.items()]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sys.exit(main())"
      ],
      "metadata": {
        "id": "ku82gBmYnbQa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}